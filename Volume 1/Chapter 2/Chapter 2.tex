\documentclass[12pt, letterpaper]{article}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[a4paper, total={6in, 8in}]{geometry}

\author{Adam Crowe}
\title{Shreve -- Stochastic Calculus for Finance, Vol. 1 \\ Chapter 2 Solutions}

\renewcommand{\arraystretch}{1.5}

\begin{document}

\maketitle

\vspace{5mm}
\noindent
\textbf{Problem 2.1}

\vspace{5mm}
\noindent
(i)$\;$ We have:
\begin{gather*}
    \mathbb P(A) + \mathbb P(A^C) =
    \sum_{\omega \in A} \mathbb P(\omega) + \sum_{\omega \in A^C} \mathbb P(\omega)=
    \sum_{\omega \in A} \mathbb P(\omega) + \sum_{\omega \in \Omega \setminus A} \mathbb P(\omega)
    = \sum_{\omega \in \Omega} \mathbb P(\omega) = 1
\end{gather*}
The result follows.

\rightline{$\square$}

\vspace{5mm}
\noindent
(ii)$\;$ We have:
\begin{gather*}
    \mathbb P \left( \, \bigcup_{n=1}^N A_n \right)
    = \sum_{\omega \in \bigcup A_n} \mathbb P(\omega)
    = \sum_{\omega \in \tilde A_1} \mathbb P(\omega)
    + \cdots
    +\sum_{\omega \in \tilde A_n } \mathbb P(\omega)
    = \mathbb P(\tilde A_1) + \cdots + \mathbb P(\tilde A_n)
\end{gather*}
where $\tilde A_n = A_n \setminus \left( \, \bigcup_{1 \leq i < n} A_i \, \right)$.
We then see that:
\begin{gather*}
    \mathbb P(\tilde A_n) = \mathbb P(A_n) - \mathbb P\left( A_n \cap \left(\bigcup_{i=1}^{n-1} A_i \right) \right)
    \leq \mathbb P(A_n)
\end{gather*}
by non-negativity of $\mathbb P$.
Thus $\mathbb P(\tilde A_n) \leq \mathbb P(A_n)$ for all $1 \leq n \leq n$, so:
\begin{gather*}
    \mathbb P \left( \, \bigcup_{n=1}^N A_n \right)
    = \sum_{n=1}^N \mathbb P(\tilde A_n) \leq \sum_{n=1}^N \mathbb P(A_n).
\end{gather*}

\vspace{5mm}
Furthermore, if all $A_n$ are disjoint, then $\tilde A_n = A_n$, which makes equality hold.

\rightline{$\square$}

\vspace{5mm}
\noindent
\textbf{Problem 2.2} $\;$ 

\vspace{5mm}
\noindent
(i)$\;$ We have:
\begin{align*}
    \tilde{\mathbb P} \{ S_3 = 32 \} &= 0.125 & \tilde{\mathbb P} \{ S_3 = 8 \} &= 0.375 \\
    \tilde{\mathbb P} \{ S_3 = 2 \} &= 0.375 & \tilde{\mathbb P} \{ S_3 = 0.5 \} &= 0.125
\end{align*}

\rightline{$\square$}

\vspace{5mm}
\noindent
(ii)$\;$ First we compute the distributions of $S_1$ and $S_2$:
\begin{align*}
    \tilde{\mathbb P} \{ S_1 = 8 \} &= 0.5 & \tilde{\mathbb P} \{ S_1 = 2 \} &= 0.5
\end{align*}
\begin{align*}
    \tilde{\mathbb P} \{ S_2 =  16\} &= 0.25 & \tilde{\mathbb P} \{ S_2 = 4 \} &= 0.5
    & \tilde{\mathbb P} \{ S_2 = 1 \} &= 0.25
\end{align*}
Then:
\begin{align*}
    \tilde{\mathbb E} S_1 &= (8)(0.5)+(2)(0.5) = 5 \\
    \tilde{\mathbb E} S_2 &= (16)(0.25)+(4)(0.5) + 1(0.25) = 6.25 \\
    \tilde{\mathbb E} S_3 &= (32)(0.125)+(8)(0.375)+(2)(0.375)+(0.5)(0.125) = 7.8125
\end{align*}
i.e: $\tilde{\mathbb E} S_n = (1+r)S_{n-1}$.

\rightline{$\square$}

\vspace{5mm}
\noindent
(iii)$\;$ The distributions are:
\begin{align*}
    \mathbb P \{ S_1 = 8 \} &= \tfrac 2 3 & \mathbb P \{ S_1 = 2 \} &= \tfrac 1 3
\end{align*}
\begin{align*}
    \mathbb P \{ S_2 =  16\} &= \tfrac 4 9 & \mathbb P \{ S_2 = 4 \} &= \tfrac 4 9
    & \mathbb P \{ S_2 = 1 \} &= \tfrac 1 9
\end{align*}
\begin{align*}
    \mathbb P \{ S_3 = 32 \} &= \tfrac 8 {27}  & \mathbb P \{ S_3 = 8 \} &= \tfrac 4 9  \\
    \mathbb P \{ S_3 = 2 \} &= \tfrac 2 9 & \mathbb P \{ S_3 = 0.5 \} &= \tfrac 1 {27}
\end{align*}
And so:
\begin{align*}
    \mathbb E S_1 &= (8) \left(\tfrac 2 3 \right)+(2)\left(\tfrac 1 3 \right) = 6 \\
    \mathbb E S_2 &= (16)\left(\tfrac 4 9 \right)+(4)\left(\tfrac 4 9 \right) + 1\left(\tfrac 1 9 \right) = 9 \\
    \mathbb E S_3 &= (32)\left(\tfrac 8 {27} \right)+(8)\left(\tfrac 4 9 \right)+(2)\left(\tfrac 2 9 \right)+(0.5)\left(\tfrac 1 {27} \right) = 13.5
\end{align*}

\vspace{5mm}
\noindent
\textbf{Problem 2.3} $\;$ Let $M_0, M_1, \dots, M_n$ be a martingale and let $\varphi$ be a convex function.

\begin{align*}
    \overset{\text{Martingale}}\implies \quad M_n &= \mathbb E_n M_{n+1} \\
    \overset{\varphi(\cdots)}\implies \quad \varphi \left( M_n \right) &= \varphi \left( \mathbb E_n M_{n+1} \right) \\
    \overset{\text{Jensen's Ineq.}}\implies \quad \varphi \left( M_n \right) &= \varphi \left( \mathbb E_n M_{n+1} \right) \leq \mathbb E_n \left[ \varphi (M_{n+1})\right]
\end{align*}
Thus for $n = 0, 1, \dots, N-1$, we have $\varphi \left( M_n \right) \leq \mathbb E_n \left[ \varphi (M_{n+1})\right]$,
so that $\varphi(M_0), \varphi(M_1),$
$\dots, \varphi(M_n)$ is a submartingale.

\rightline{$\square$}

\vspace{5mm}
\noindent
\textbf{Problem 2.4}

\vspace{5mm}
\noindent
(i)$\;$ If $M_{n+1}(H), M_{n+1}(T)$ are the values of $M_{n+1}$ depending on whether the outcome of the $n$-th toss is heads or tails respectively, then we have:

\begin{align*}
    M_{n+1}(H) = M_n + 1, \quad \quad M_{n+1}(T) = M_n - 1
\end{align*}
Thus with the given probabilities:
\begin{gather*}
    \mathbb E_n M_{n+1} = \tfrac 1 2 (M_n +1) + \tfrac 1 2 (M_n - 1) = M_n
\end{gather*}
Therefore $M_0, M_1, M_2, \dots$ is a martingale.

\rightline{$\square$}

\vspace{5mm}
\noindent
(ii)$\;$Again:
\begin{gather*}
    S_{n+1} = e^{\sigma \left( M_n \,\pm\, 1\right)} \left( \frac{2}{e^\sigma + e^{-\sigma}}\right)^{n+1} = e^{\pm \, \sigma} \cdot e^{\sigma M_n} \cdot \left( \frac{2}{e^\sigma + e^{-\sigma}}\right) \cdot \left( \frac{2}{e^\sigma + e^{-\sigma}}\right)^{n} \\
    = e^{\pm \, \sigma} \left( \frac{2}{e^\sigma + e^{-\sigma}}\right) \cdot S_n
\end{gather*}
\begin{align*}
    \mathbb E_n S_{n+1} &= \tfrac{1}{2} \left( e^{\sigma} \left( \frac{2}{e^\sigma + e^{-\sigma}}\right) \cdot S_n \right)
    + \tfrac{1}{2} \left( e^{-\sigma} \left( \frac{2}{e^\sigma + e^{-\sigma}}\right) \cdot S_n \right) \\
    &= \left( \frac{e^\sigma}{e^\sigma + e^{-\sigma}} \right) S_n + \left( \frac{e^{-\sigma}}{e^\sigma + e^{-\sigma}} \right) S_n = S_n
\end{align*}
Therefore $S_0, S_1, S_2, \dots$ is a martingale.

\rightline{$\square$}

\vspace{5mm}
\noindent
\textbf{Problem 2.5}

\vspace{5mm}
\noindent
(i)$\;$We notice that $M_{j+1} - M_j = X_{j+1}$. Furthermore, $M_0 = 0$ so we can change the starting index of the sum to $j=1$. Therefore:
\begin{gather*}
    I_n = \sum_{j=1}^{n-1} M_j X_{j+1} = \sum_{j=1}^{n-1} \left( \left(\sum_{i=1}^j X_i \right) X_{j+1}\right) = \sum_{1 \leq i < j}^{n} X_i X_j
\end{gather*}
To see the last equality, notice that $X_{j+1}$ is multiplied by exactly once every by $X_i$ from $1$ to $j$.
We have:
\begin{gather*}
    M_n^2 = \left( \sum_{j=1}^n X_j \right)^2 = \sum_{j=1}^n X_j^2 + 2 \sum_{1 \leq i < j} X_i X_j = \sum_{j=1}^n X_j^2 + 2I_n
\end{gather*}
Since each $X_j = \pm 1$, we have $X_j^2 = 1$. Therefore:
\begin{gather*}
    M_n^2 = n + 2I_n \quad \implies \quad I_n = \tfrac 1 2 M_n^2 - \tfrac n 2
\end{gather*}

\rightline{$\square$}

\vspace{5mm}
\noindent
(ii)$\;$ We have:
\begin{gather*}
    I_{n+1} = \tfrac{1}{2} \left( M_n \pm 1\right)^2 - \tfrac 1 2 (n+1) = \tfrac 1 2 M_n^2 \pm M_n + \tfrac 1 2 - \tfrac n 2 - \tfrac 1 2 = I_n \pm M_n
\end{gather*}
\begin{gather*}
    \therefore \quad \mathbb E_n \left[ f \left( I_{n+1} \right) \right] = \tfrac 1 2 f(I_n + M_n) + \tfrac 1 2 f(I_n - M_n)
\end{gather*}
We want the LHS to be entirely in terms of $I_n$ so use (i) to re-write $M_n = \sqrt{2I_n + n}$.
Note that we can simply let $M_n$ be the positive square root as the above equation is unchanged if we let $M_n' = -M_n$.
Therefore our function $g(i)$ is:
\begin{gather*}
    g(i) = \tfrac 1 2 f \left( i + \sqrt{2i - n} \right) + \tfrac 1 2 f \left( i - \sqrt{2i - n} \right)
\end{gather*}

\rightline{$\square$}

\vspace{5mm}
\noindent
\textbf{Problem 2.6} $\;$ We calculate:
\begin{align*}
    \mathbb E_n I_{n+1} &= \mathbb E_n \left[ \sum_{j=0}^n \Delta_j (M_{j+1} - M_j) \right] \\
    &= \mathbb E_n \left[ \Delta_n (M_{n+1} - M_n) \right] + \sum_{j=0}^{n-1} \Delta_j (M_{j+1} - M_j) \\
    &= \mathbb E_n \left[ \Delta_n (M_{n+1} - M_n) \right] + I_n
\end{align*}
where in the second equality we have used the linearity and the `taking out what is known' properties of conditional expectations.
Then:
\begin{gather*}
    \mathbb E_n \left[ \Delta_n (M_{n+1} - M_n) \right] = \mathbb E_n \left[ \Delta_n M_{n+1} \right] - \mathbb E_n \left[\Delta_n  M_n \right] = \Delta_n \mathbb E_n M_{n+1} - \Delta_n M_n
\end{gather*}
but since $M_0, M_1, \dots, M_N$ is a martingale, $\mathbb E_n M_{n+1} = M_n$, meaning the terms on the RHS cancel.
Therefore $\mathbb E_n I_{n+1} = I_n$, and $I_0, I_1, \dots, I_N$ is a martingale.

\rightline{$\square$}

\end{document}